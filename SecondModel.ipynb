{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937
        },
        "id": "CmXSAcux2uvh",
        "outputId": "eef1dc6d-5460-46b2-df22-812a5dddbac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nlastnum = scaler.inverse_transform(model.predict(x_train))[-1]\\nlastone = (lastnum)**2\\nlastdata = data_gbpusd[-1]**2\\nprint(lastone - lastdata)\\nprint(lastnum - data_gbpusd[-1])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas_datareader as pdr\n",
        "import math\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "from pandas_datareader import data as pdr\n",
        "# Define start and end dates\n",
        "end_date = '2018-01-01'\n",
        "start_date = '2001-01-01'\n",
        "\n",
        "# Get the close prices for GBPUSD\n",
        "df_gbpusd = pdr.get_data_yahoo('GBPUSD=X', start=start_date, end=end_date)\n",
        "data_gbpusd = df_gbpusd.values\n",
        "yfilter = df_gbpusd.filter(['Close']).values\n",
        "# Get the close prices for SPX500\n",
        "df_spx500 = pdr.get_data_yahoo('^GSPC', start=start_date, end=end_date)\n",
        "data_spx500 = df_spx500.values\n",
        "\n",
        "# Find the minimum length between the two datasets\n",
        "min_length = min(len(data_gbpusd), len(data_spx500))\n",
        "\n",
        "# Truncate the longer dataset to match the minimum length\n",
        "data_gbpusd = data_gbpusd[:min_length]\n",
        "data_spx500 = data_spx500[:min_length]\n",
        "\n",
        "# Take every 7th element from the truncated datasets\n",
        "data_gbpusd = data_gbpusd[::]\n",
        "data_spx500 = data_spx500[::]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Get the close prices for USDMXN (MXN=X)\n",
        "df_usdmxn = pdr.get_data_yahoo('MXN=X', start=start_date, end=end_date)\n",
        "data_usdmxn = df_usdmxn.values\n",
        "data_usdmxn = data_usdmxn[:min_length]\n",
        "data_usdmxn = data_usdmxn[::]\n",
        "\n",
        "# Get the close prices for USDCAD (CAD=X)\n",
        "df_usdcad = pdr.get_data_yahoo('CAD=X', start=start_date, end=end_date)\n",
        "data_usdcad = df_usdcad.values\n",
        "data_usdcad = data_usdcad[:min_length]\n",
        "data_usdcad = data_usdcad[::]\n",
        "\n",
        "# Get the close prices for USDCNY (CNY=X)\n",
        "df_usdcny = pdr.get_data_yahoo('CNY=X', start=start_date, end=end_date)\n",
        "data_usdcny = df_usdcny.values\n",
        "data_usdcny = data_usdcny[:min_length]\n",
        "data_usdcny = data_usdcny[::]\n",
        "\n",
        "# Get the close prices for VIX (%5EVIX)\n",
        "df_vix = pdr.get_data_yahoo('%5EVIX', start=start_date, end=end_date)\n",
        "data_vix = df_vix.values\n",
        "data_vix = data_vix[:min_length]\n",
        "data_vix = data_vix[::]\n",
        "def data(dataName):\n",
        "  df_data = pdr.get_data_yahoo(dataName, start=start_date, end=end_date)\n",
        "  data_data = df_data.values\n",
        "  data_data = data_data[:min_length]\n",
        "  data_data = data_data[::]\n",
        "  return data_data\n",
        "# Concatenate all the lists\n",
        "lists = [data_spx500, data_usdmxn, data_usdcad, data_usdcny, data_vix,\n",
        "         data('EURUSD%3DX'), data('AUDUSD%3DX'), data('NZDUSD%3DX'),\n",
        "         data('EURJPY%3DX'), data('GBPJPY%3DX'), data('EURGBP%3DX'), data('EURCAD%3DX'),\n",
        "         data('EURSEK%3DX'), data('EURCHF%3DX'), data('%5ETNX'), data('%5EDJI'),\n",
        "         data('%5EIXIC'), data('CL%3DF'), data('GC%3DF'), data('%5EFVX'), data('%5ETYX'),\n",
        "         data('%5EFTSE'), data('%5ENYA'), data('%5EXAX'), data('%5ERUT'), data('%5EGDAXI'),\n",
        "         data('%5EFCHI'), data('%5ESTOXX50E'), data('%5EN100'), data('%5EBFX'),\n",
        "         data('%5EN225'), data('%5EHSI'), data('000001.SS'), data('399001.SZ'), data('%5ESTI'),\n",
        "         data('%5EAXJO'), data('%5EAORD'), data('%5EBSESN'), data('%5EJKSE'), data('%5EKLSE'),\n",
        "         data('%5ENZ50'), data('%5EKS11'), data('%5ETWII'), data('%5EGSPTSE'), data('%5EBVSP'),\n",
        "         data('%5EMXX'), data('%5EIPSA'), data('%5EMERV'), data('%5ETA125.TA'), data('%5EIRX')]\n",
        "\n",
        "\n",
        "# Find the maximum length among all lists\n",
        "max_length = max(len(lst) for lst in lists)\n",
        "\n",
        "# Resize lists to have the maximum length\n",
        "resized_lists = [np.resize(lst, (max_length, 1)) for lst in lists]\n",
        "\n",
        "# Concatenate the resized lists\n",
        "data_combined = np.concatenate(resized_lists, axis=1)\n",
        "\"\"\"\n",
        "data_combined = np.concatenate((data_gbpusd, data_spx500, data_usdmxn, data_usdcad, data_usdcny, data_vix, data('EURUSD%3DX'), data('AUDUSD%3DX'), data('NZDUSD%3DX'), data('EURJPY%3DX'), data('GBPJPY%3DX'), data('EURGBP%3DX'), data('EURCAD%3DX'), data('EURSEK%3DX'), data('EURCHF%3DX'),  data('%5ETNX'), data('%5EDJI'), data('%5EIXIC'), data('CL%3DF'), data('GC%3DF'), data('%5EFVX'), data('%5ETYX'), data('%5EFTSE'), data('%5ENYA'), data('%5EXAX'), data('%5ERUT'), data('%5EGDAXI'), data('%5EFCHI'), data('%5ESTOXX50E'), data('%5EN100'), data('%5EBFX'), data('%5EN225'), data('%5EHSI'), data('000001.SS'), data('399001.SZ'), data('%5ESTI'), data('%5EAXJO'), data('%5EAORD'), data('%5EBSESN'), data('%5EJKSE'), data('%5EKLSE'), data('%5ENZ50'), data('%5EKS11'), data('%5ETWII'), data('%5EGSPTSE'), data('%5EBVSP'), data('%5EMXX'), data('%5EIPSA'), data('%5EMERV'), data('%5ETA125.TA')), axis=1)\n",
        "\"\"\"\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(data_combined)\n",
        "scalegbpusd = scaler.fit_transform(data_gbpusd)\n",
        "scaley = scaler.fit_transform(yfilter)\n",
        "# Define training data length\n",
        "training_data_len = math.ceil(len(data_combined) * .8)\n",
        "\n",
        "# Create the training data set\n",
        "train_data = scaled_data[0:training_data_len, :]\n",
        "scalegbpusd = scalegbpusd[0:training_data_len, :]\n",
        "yfilter = yfilter[0:training_data_len, :]\n",
        "# Split data into x_train and y_train\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(60, len(train_data)):\n",
        "    x_train.append(train_data[i - 60:i, :])\n",
        "    y_train.append(yfilter[i, 0])\n",
        "\n",
        "# Convert x_train and y_train to numpy arrays\n",
        "x_train, y_train = np.array(x_train), np.array(y_train)\n",
        "\n",
        "# Reshape x_train for LSTM input\n",
        "x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 50))\n",
        "\"\"\"\n",
        "lastnum = scaler.inverse_transform(model.predict(x_train))[-1]\n",
        "lastone = (lastnum)**2\n",
        "lastdata = data_gbpusd[-1]**2\n",
        "print(lastone - lastdata)\n",
        "print(lastnum - data_gbpusd[-1])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(x_train)\n",
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLCCNkew05DW",
        "outputId": "00326cbc-e8a3-447b-e75c-c2e872e868ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90/90 [==============================] - 16s 163ms/step\n",
            "2868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SkiDqrrKCLbp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "6030f976-f582-4b69-80ff-20b102393320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.85911608 1.86839044 1.89000189 ... 1.52483189 1.50579739 1.5108707 ]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-b18c167f3f69>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtestdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'MinMaxScaler' object has no attribute 'min_'"
          ]
        }
      ],
      "source": [
        "testdata = data_gbpusd[60:training_data_len, :]\n",
        "testdata = testdata[:, 0]\n",
        "print(testdata)\n",
        "print(scaler.inverse_transform(predictions))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWq4iIl6tyZj",
        "outputId": "59a445b4-1e43-466c-ead5-388cf08ca879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done adding\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import GRU\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(GRU(500, return_sequences=True, input_shape=(x_train.shape[1], 50)))\n",
        "model.add(GRU(250, return_sequences=False))\n",
        "model.add(Dense(200))\n",
        "model.add(Dense(150))\n",
        "model.add(Dense(100))\n",
        "model.add(Dense(75))\n",
        "model.add(Dense(50))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(25))\n",
        "model.add(Dense(1))\n",
        "\n",
        "\n",
        "\n",
        "# Compile the model\n",
        "print('Done adding')\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=[tf.keras.metrics.Accuracy()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2k4A_ACeGNh"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Load the model from the SavedModel format\n",
        "model = keras.models.load_model('crutchless8.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ15Da9CVLjg",
        "outputId": "8b7185ed-5850-4266-90fa-3fd9318dde93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "956/956 [==============================] - 227s 238ms/step - loss: 7.6420e-04 - accuracy: 3.4868e-04\n",
            "Epoch 2/15\n",
            "956/956 [==============================] - 227s 238ms/step - loss: 1.5995e-04 - accuracy: 0.0000e+00\n",
            "Epoch 3/15\n",
            "956/956 [==============================] - 226s 237ms/step - loss: 1.9607e-04 - accuracy: 0.0000e+00\n",
            "Epoch 4/15\n",
            "956/956 [==============================] - 226s 237ms/step - loss: 2.1604e-04 - accuracy: 0.0000e+00\n",
            "Epoch 5/15\n",
            "956/956 [==============================] - 227s 238ms/step - loss: 2.9198e-04 - accuracy: 0.0000e+00\n",
            "Epoch 6/15\n",
            "956/956 [==============================] - 226s 237ms/step - loss: 2.0151e-04 - accuracy: 0.0000e+00\n",
            "Epoch 7/15\n",
            "956/956 [==============================] - 242s 253ms/step - loss: 2.6511e-04 - accuracy: 0.0000e+00\n",
            "Epoch 8/15\n",
            "956/956 [==============================] - 239s 250ms/step - loss: 6.7103e-04 - accuracy: 0.0000e+00\n",
            "Epoch 9/15\n",
            "956/956 [==============================] - 231s 241ms/step - loss: 1.6960e-04 - accuracy: 0.0000e+00\n",
            "Epoch 10/15\n",
            "956/956 [==============================] - 233s 244ms/step - loss: 1.5846e-04 - accuracy: 0.0000e+00\n",
            "Epoch 11/15\n",
            "956/956 [==============================] - 232s 243ms/step - loss: 2.3791e-04 - accuracy: 0.0000e+00\n",
            "Epoch 12/15\n",
            "956/956 [==============================] - 230s 241ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
            "Epoch 13/15\n",
            " 92/956 [=>............................] - ETA: 3:30 - loss: 3.1658e-04 - accuracy: 0.0000e+00"
          ]
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=3, epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRDsy2eVuXY5",
        "outputId": "9ae28ebb-db3f-4c04-a506-f4adb3276caa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "71/71 [==============================] - 23s 296ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[44.958176],\n",
              "       [45.16594 ],\n",
              "       [45.325493],\n",
              "       ...,\n",
              "       [45.337013],\n",
              "       [45.36002 ],\n",
              "       [44.921272]], dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(x_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiWNHe_CPyNQ",
        "outputId": "422d0de5-0500-4fd8-c52d-4fc8b6215e49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "956/956 [==============================] - 335s 350ms/step - loss: 8.6107e-04 - accuracy: 0.0000e+00\n",
            "Epoch 2/5\n",
            "956/956 [==============================] - 341s 357ms/step - loss: 0.0093 - accuracy: 0.0000e+00\n",
            "Epoch 3/5\n",
            "956/956 [==============================] - 336s 351ms/step - loss: 0.0038 - accuracy: 0.0000e+00\n",
            "Epoch 4/5\n",
            "956/956 [==============================] - 330s 345ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
            "Epoch 5/5\n",
            "956/956 [==============================] - 335s 350ms/step - loss: 0.0046 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86e6e0b0d0>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=3, epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6sin7oJQatv",
        "outputId": "9990185b-264a-4a5e-b74e-c7e7077b0462"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "956/956 [==============================] - 365s 382ms/step - loss: 0.0015 - accuracy: 0.0000e+00\n",
            "Epoch 2/30\n",
            "956/956 [==============================] - 351s 367ms/step - loss: 0.0013 - accuracy: 0.0000e+00\n",
            "Epoch 3/30\n",
            "956/956 [==============================] - 348s 364ms/step - loss: 0.0014 - accuracy: 0.0000e+00\n",
            "Epoch 4/30\n",
            "956/956 [==============================] - 343s 359ms/step - loss: 0.0011 - accuracy: 0.0000e+00\n",
            "Epoch 5/30\n",
            "956/956 [==============================] - 341s 356ms/step - loss: 0.0018 - accuracy: 0.0000e+00\n",
            "Epoch 6/30\n",
            "956/956 [==============================] - 340s 355ms/step - loss: 9.9328e-04 - accuracy: 0.0000e+00\n",
            "Epoch 7/30\n",
            "956/956 [==============================] - 339s 354ms/step - loss: 9.4335e-04 - accuracy: 0.0000e+00\n",
            "Epoch 8/30\n",
            "956/956 [==============================] - 349s 365ms/step - loss: 8.6606e-04 - accuracy: 0.0000e+00\n",
            "Epoch 9/30\n",
            "956/956 [==============================] - 343s 359ms/step - loss: 0.0023 - accuracy: 0.0000e+00\n",
            "Epoch 10/30\n",
            "956/956 [==============================] - 345s 361ms/step - loss: 7.8679e-04 - accuracy: 0.0000e+00\n",
            "Epoch 11/30\n",
            "956/956 [==============================] - 349s 365ms/step - loss: 7.8593e-04 - accuracy: 0.0000e+00\n",
            "Epoch 12/30\n",
            "956/956 [==============================] - 344s 360ms/step - loss: 6.1562e-04 - accuracy: 0.0000e+00\n",
            "Epoch 13/30\n",
            "956/956 [==============================] - 346s 362ms/step - loss: 7.8952e-04 - accuracy: 0.0000e+00\n",
            "Epoch 14/30\n",
            "956/956 [==============================] - 339s 355ms/step - loss: 6.3132e-04 - accuracy: 0.0000e+00\n",
            "Epoch 15/30\n",
            "956/956 [==============================] - 343s 359ms/step - loss: 5.7394e-04 - accuracy: 0.0000e+00\n",
            "Epoch 16/30\n",
            "956/956 [==============================] - 344s 360ms/step - loss: 0.0021 - accuracy: 0.0000e+00\n",
            "Epoch 17/30\n",
            "956/956 [==============================] - 339s 355ms/step - loss: 5.5918e-04 - accuracy: 0.0000e+00\n",
            "Epoch 18/30\n",
            "956/956 [==============================] - 345s 361ms/step - loss: 5.1564e-04 - accuracy: 0.0000e+00\n",
            "Epoch 19/30\n",
            "956/956 [==============================] - 345s 361ms/step - loss: 5.9704e-04 - accuracy: 0.0000e+00\n",
            "Epoch 20/30\n",
            "956/956 [==============================] - 341s 357ms/step - loss: 5.7689e-04 - accuracy: 0.0000e+00\n",
            "Epoch 21/30\n",
            "956/956 [==============================] - 336s 352ms/step - loss: 6.1844e-04 - accuracy: 0.0000e+00\n",
            "Epoch 22/30\n",
            "956/956 [==============================] - 343s 359ms/step - loss: 4.9493e-04 - accuracy: 0.0000e+00\n",
            "Epoch 23/30\n",
            "956/956 [==============================] - 342s 357ms/step - loss: 4.7448e-04 - accuracy: 0.0000e+00\n",
            "Epoch 24/30\n",
            "956/956 [==============================] - 340s 355ms/step - loss: 0.0011 - accuracy: 0.0000e+00\n",
            "Epoch 25/30\n",
            "956/956 [==============================] - 335s 350ms/step - loss: 4.4504e-04 - accuracy: 0.0000e+00\n",
            "Epoch 26/30\n",
            "956/956 [==============================] - 334s 349ms/step - loss: 3.7724e-04 - accuracy: 0.0000e+00\n",
            "Epoch 27/30\n",
            "956/956 [==============================] - 340s 355ms/step - loss: 4.0855e-04 - accuracy: 0.0000e+00\n",
            "Epoch 28/30\n",
            "956/956 [==============================] - 337s 352ms/step - loss: 4.1168e-04 - accuracy: 0.0000e+00\n",
            "Epoch 29/30\n",
            "956/956 [==============================] - 334s 349ms/step - loss: 0.0050 - accuracy: 0.0000e+00\n",
            "Epoch 30/30\n",
            "956/956 [==============================] - 332s 348ms/step - loss: 0.0055 - accuracy: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f86e6dfbc40>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(x_train, y_train, batch_size=3, epochs=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Scrs8YALLFHt"
      },
      "outputs": [],
      "source": [
        "model.save('crutchless8.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "make one where the y_train is the change in slope\n"
      ],
      "metadata": {
        "id": "44WEcLiBfbNz"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}