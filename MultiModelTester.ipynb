{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S6UfeUt1wEBh",
        "outputId": "7962e094-4f15-4d44-ac7a-198982b793a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-1c535542eb49>\u001b[0m in \u001b[0;36m<cell line: 259>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0mscaler_gbpusd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0mscaler_spx500\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m \u001b[0mmodelPredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maddWeek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-1c535542eb49>\u001b[0m in \u001b[0;36mmodelPredict\u001b[0;34m(end_date)\u001b[0m\n\u001b[1;32m    150\u001b[0m   \u001b[0;31m# Convert x_train and y_train to numpy arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m   \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m   \u001b[0mx_train3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m   \u001b[0;31m# Reshape x_train for LSTM input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m49\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    296\u001b[0m            [5, 6]])\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 14711760 into shape (5004,60,50)"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas_datareader as pdr\n",
        "import math\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "import yfinance as yf\n",
        "yf.pdr_override()\n",
        "from pandas_datareader import data as pdr\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "import datetime\n",
        "\n",
        "# Load the model from the SavedModel format\n",
        "\n",
        "def modelPredict(end_date):\n",
        "  # Define start and end dates\n",
        "  start_date = '2001-01-01'\n",
        "\n",
        "  # Get the close prices for GBPUSD\n",
        "  df_gbpusd = pdr.get_data_yahoo('GBPUSD=X', start=start_date, end=end_date)\n",
        "  data_gbpusd = df_gbpusd.values\n",
        "\n",
        "  # Get the close prices for SPX500\n",
        "  df_spx500 = pdr.get_data_yahoo('^GSPC', start=start_date, end=end_date)\n",
        "  data_spx500 = df_spx500.values\n",
        "\n",
        "  # Find the minimum length between the two datasets\n",
        "  min_length = min(len(data_gbpusd), len(data_spx500))\n",
        "\n",
        "  # Truncate the longer dataset to match the minimum length\n",
        "  data_gbpusd = data_gbpusd[:min_length]\n",
        "  data_spx500 = data_spx500[:min_length]\n",
        "\n",
        "  # Take every 7th element from the truncated datasets\n",
        "  data_gbpusd = data_gbpusd[::]\n",
        "  data_spx500 = data_spx500[::]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  # Get the close prices for USDMXN (MXN=X)\n",
        "  df_usdmxn = pdr.get_data_yahoo('MXN=X', start=start_date, end=end_date)\n",
        "  data_usdmxn = df_usdmxn.values\n",
        "  data_usdmxn = data_usdmxn[:min_length]\n",
        "  data_usdmxn = data_usdmxn[::]\n",
        "\n",
        "  # Get the close prices for USDCAD (CAD=X)\n",
        "  df_usdcad = pdr.get_data_yahoo('CAD=X', start=start_date, end=end_date)\n",
        "  data_usdcad = df_usdcad.values\n",
        "  data_usdcad = data_usdcad[:min_length]\n",
        "  data_usdcad = data_usdcad[::]\n",
        "\n",
        "  # Get the close prices for USDCNY (CNY=X)\n",
        "  df_usdcny = pdr.get_data_yahoo('CNY=X', start=start_date, end=end_date)\n",
        "  data_usdcny = df_usdcny.values\n",
        "  data_usdcny = data_usdcny[:min_length]\n",
        "  data_usdcny = data_usdcny[::]\n",
        "\n",
        "  # Get the close prices for VIX (%5EVIX)\n",
        "  df_vix = pdr.get_data_yahoo('%5EVIX', start=start_date, end=end_date)\n",
        "  data_vix = df_vix.values\n",
        "  data_vix = data_vix[:min_length]\n",
        "  data_vix = data_vix[::]\n",
        "  def data(dataName):\n",
        "    df_data = pdr.get_data_yahoo(dataName, start=start_date, end=end_date)\n",
        "    data_data = df_data.values\n",
        "    data_data = data_data[:min_length]\n",
        "    data_data = data_data[::]\n",
        "    return data_data\n",
        "  # Concatenate all the lists\n",
        "  lists = [data_spx500, data_usdmxn, data_usdcad, data_usdcny, data_vix,\n",
        "          data('EURUSD%3DX'), data('AUDUSD%3DX'), data('NZDUSD%3DX'),\n",
        "          data('EURJPY%3DX'), data('GBPJPY%3DX'), data('EURGBP%3DX'), data('EURCAD%3DX'),\n",
        "          data('EURSEK%3DX'), data('EURCHF%3DX'), data('%5ETNX'), data('%5EDJI'),\n",
        "          data('%5EIXIC'), data('CL%3DF'), data('GC%3DF'), data('%5EFVX'), data('%5ETYX'),\n",
        "          data('%5EFTSE'), data('%5ENYA'), data('%5EXAX'), data('%5ERUT'), data('%5EGDAXI'),\n",
        "          data('%5EFCHI'), data('%5ESTOXX50E'), data('%5EN100'), data('%5EBFX'),\n",
        "          data('%5EN225'), data('%5EHSI'), data('000001.SS'), data('399001.SZ'), data('%5ESTI'),\n",
        "          data('%5EAXJO'), data('%5EAORD'), data('%5EBSESN'), data('%5EJKSE'), data('%5EKLSE'),\n",
        "          data('%5ENZ50'), data('%5EKS11'), data('%5ETWII'), data('%5EGSPTSE'), data('%5EBVSP'),\n",
        "          data('%5EMXX'), data('%5EIPSA'), data('%5EMERV'), data('%5ETA125.TA')]\n",
        "  lists2 = [data_gbpusd, data_spx500, data_usdmxn, data_usdcad, data_usdcny, data_vix,\n",
        "          data('EURUSD%3DX'), data('AUDUSD%3DX'), data('NZDUSD%3DX'),\n",
        "          data('EURJPY%3DX'), data('GBPJPY%3DX'), data('EURGBP%3DX'), data('EURCAD%3DX'),\n",
        "          data('EURSEK%3DX'), data('EURCHF%3DX'), data('%5ETNX'), data('%5EDJI'),\n",
        "          data('%5EIXIC'), data('CL%3DF'), data('GC%3DF'), data('%5EFVX'), data('%5ETYX'),\n",
        "          data('%5EFTSE'), data('%5ENYA'), data('%5EXAX'), data('%5ERUT'), data('%5EGDAXI'),\n",
        "          data('%5EFCHI'), data('%5ESTOXX50E'), data('%5EN100'), data('%5EBFX'),\n",
        "          data('%5EN225'), data('%5EHSI'), data('000001.SS'), data('399001.SZ'), data('%5ESTI'),\n",
        "          data('%5EAXJO'), data('%5EAORD'), data('%5EBSESN'), data('%5EJKSE'), data('%5EKLSE'),\n",
        "          data('%5ENZ50'), data('%5EKS11'), data('%5ETWII'), data('%5EGSPTSE'), data('%5EBVSP'),\n",
        "          data('%5EMXX'), data('%5EIPSA'), data('%5EMERV'), data('%5ETA125.TA')]\n",
        "  # Find the maximum length among all lists\n",
        "  def calculate_changes(arr):\n",
        "    changes = []\n",
        "\n",
        "    for i in range(1, len(arr)):\n",
        "        change = arr[i] - arr[i-1]\n",
        "        if change > 0:\n",
        "            changes.append(1)\n",
        "        elif change < 0:\n",
        "            changes.append(-1)\n",
        "        else:\n",
        "            changes.append(0)\n",
        "\n",
        "    return changes\n",
        "\n",
        "  max_length = max(len(lst) for lst in lists)\n",
        "  max_length2 = max(len(lst) for lst in lists2)\n",
        "  # Resize lists to have the maximum length\n",
        "  resized_lists = [np.resize(lst, (max_length, 1)) for lst in lists]\n",
        "  resized_lists2 = [np.resize(lst, (max_length2, 1)) for lst in lists2]\n",
        "  # Concatenate the resized lists\n",
        "  data_combined = np.concatenate(resized_lists, axis=1)\n",
        "  data_combined2 = np.concatenate(resized_lists2, axis=1)\n",
        "  \"\"\"\n",
        "  data_combined = np.concatenate((data_gbpusd, data_spx500, data_usdmxn, data_usdcad, data_usdcny, data_vix, data('EURUSD%3DX'), data('AUDUSD%3DX'), data('NZDUSD%3DX'), data('EURJPY%3DX'), data('GBPJPY%3DX'), data('EURGBP%3DX'), data('EURCAD%3DX'), data('EURSEK%3DX'), data('EURCHF%3DX'),  data('%5ETNX'), data('%5EDJI'), data('%5EIXIC'), data('CL%3DF'), data('GC%3DF'), data('%5EFVX'), data('%5ETYX'), data('%5EFTSE'), data('%5ENYA'), data('%5EXAX'), data('%5ERUT'), data('%5EGDAXI'), data('%5EFCHI'), data('%5ESTOXX50E'), data('%5EN100'), data('%5EBFX'), data('%5EN225'), data('%5EHSI'), data('000001.SS'), data('399001.SZ'), data('%5ESTI'), data('%5EAXJO'), data('%5EAORD'), data('%5EBSESN'), data('%5EJKSE'), data('%5EKLSE'), data('%5ENZ50'), data('%5EKS11'), data('%5ETWII'), data('%5EGSPTSE'), data('%5EBVSP'), data('%5EMXX'), data('%5EIPSA'), data('%5EMERV'), data('%5ETA125.TA')), axis=1)\n",
        "  \"\"\"\n",
        "  # Scale the data\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  scaled_data = scaler.fit_transform(data_combined)\n",
        "  scaled_data2 = scaler.fit_transform(data_combined2)\n",
        "  scalegbpusd = scaler.fit_transform(data_gbpusd)\n",
        "  # Define training data length\n",
        "  training_data_len = math.ceil(len(data_combined))\n",
        "  training_data_len2 = math.ceil(len(data_combined2))\n",
        "\n",
        "  # Create the training data set\n",
        "  train_data = scaled_data[0:training_data_len, :]\n",
        "  train_data2 = scaled_data2[0:training_data_len2, :]\n",
        "  scalegbpusd = scalegbpusd[0:training_data_len, :]\n",
        "  # Split data into x_train and y_train\n",
        "  x_train = []\n",
        "  x_train2 = []\n",
        "  y_train = []\n",
        "\n",
        "  for i in range(60, len(train_data)):\n",
        "      x_train.append(train_data[i - 60:i, :])\n",
        "      y_train.append(scalegbpusd[i, 0])\n",
        "\n",
        "  for i in range(60, len(train_data2)):\n",
        "      x_train2.append(train_data2[i - 60: i, :])\n",
        "  # Convert x_train and y_train to numpy arrays\n",
        "  x_train, x_train2, y_train = np.array(x_train), np.array(x_train2), np.array(y_train)\n",
        "  x_train3 = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 50))\n",
        "  # Reshape x_train for LSTM input\n",
        "  x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 49))\n",
        "  x_train2 = np.reshape(x_train2, (x_train2.shape[0], x_train2.shape[1], 50))\n",
        "  modelPredictList = model.predict(x_train)\n",
        "  modelPredictList2 = model3.predict(x_train)\n",
        "  x_train3 = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 50))\n",
        "  modelPredictList1 = model2.predict(x_train3)\n",
        "\n",
        "  buy_sell_list = []\n",
        "  modelPredictList = calculate_changes(modelPredictList[::])\n",
        "  modelPredictList1 = calculate_changes(modelPredictList1[::])\n",
        "  modelPredictList2 = calculate_changes(modelPredictList2[::])\n",
        "  closeList = df_gbpusd.filter(['Close']).values\n",
        "  closeList = closeList[:-1]\n",
        "  refList = calculate_changes(closeList)\n",
        "  for i in range(len(modelPredictList)):\n",
        "    numberBuys = 0\n",
        "    numberSells = 0\n",
        "    if modelPredictList[i] > 0:\n",
        "      numberBuys += 1\n",
        "    else:\n",
        "      numberSells += 1\n",
        "    if modelPredictList1[i] > 0:\n",
        "      numberBuys += 1\n",
        "    else:\n",
        "      numberSells += 1\n",
        "    if modelPredictList2[i] > 0:\n",
        "      numberBuys += 1\n",
        "    else:\n",
        "      numberSells += 1\n",
        "    if numberBuys > numberSells:\n",
        "        buy_sell_list.append(1)  # Append 1 indicating \"Buy\"\n",
        "    elif numberSells > numberBuys:\n",
        "        buy_sell_list.append(-1)  # Append -1 indicating \"Sell\"\n",
        "    else:\n",
        "        buy_sell_list.append(0)\n",
        "  def calculate_percentage(list1, list2):\n",
        "    if len(list1) != len(list2):\n",
        "        raise ValueError(\"Input lists must have the same length.\")\n",
        "\n",
        "    count = 0\n",
        "    countzeroes = 0\n",
        "    for num1, num2 in zip(list1, list2):\n",
        "        if num1 * num2 < 0:\n",
        "            count += 1\n",
        "        if num1 * num2 == 0:\n",
        "          countzeroes += 1\n",
        "\n",
        "    percentage = (count / (len(list1) - countzeroes)) * 100\n",
        "    return percentage\n",
        "\n",
        "  buy_sell_actual = refList\n",
        "  print(buy_sell_actual)\n",
        "  print(buy_sell_list)\n",
        "  print(calculate_percentage(buy_sell_list[3500:], buy_sell_actual[3559:]))\n",
        "\n",
        "  lastnum = modelPredictList[-1]\n",
        "  lastnum2 = modelPredictList[-2]\n",
        "  lastnum1 = modelPredictList1[-1]\n",
        "  lastnum12 = modelPredictList1[-2]\n",
        "  lastnum21 = modelPredictList2[-1]\n",
        "  lastnum22 = modelPredictList2[-2]\n",
        "  print(end_date)\n",
        "  print(lastnum - lastnum2)\n",
        "  numberBuys = 0\n",
        "  numberSells = 0\n",
        "  if lastnum > lastnum2:\n",
        "    print('Crutchless: Buy')\n",
        "    numberBuys += 1\n",
        "  else:\n",
        "    print('Crutchless: Sell')\n",
        "    numberSells += 1\n",
        "  print(lastnum1 - lastnum12)\n",
        "  if lastnum1 > lastnum12:\n",
        "    numberBuys += 1\n",
        "    print('All Data: Buy')\n",
        "  else:\n",
        "    numberSells += 1\n",
        "    print('All Data: Sell')\n",
        "  print(lastnum21 - lastnum22)\n",
        "  if lastnum21 > lastnum22:\n",
        "    numberBuys += 1\n",
        "\n",
        "    print('Bi: Buy')\n",
        "  else:\n",
        "    numberSells += 1\n",
        "  if(numberBuys > numberSells):\n",
        "    print('Buy')\n",
        "  else:\n",
        "    print('Sell')\n",
        "\n",
        "def addWeek(date_str):\n",
        "    date_obj = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()\n",
        "    adjusted_date = date_obj + datetime.timedelta(days=1)  # Start from the next day\n",
        "\n",
        "    # Skip weekends\n",
        "    while adjusted_date.weekday() >= 5:  # 5 and 6 correspond to Saturday and Sunday\n",
        "        adjusted_date += datetime.timedelta(days=1)\n",
        "\n",
        "    adjusted_date_str = adjusted_date.strftime('%Y-%m-%d')\n",
        "    return adjusted_date_str\n",
        "\n",
        "# Define separate scalers for GBPUSD and SPX500\n",
        "n = '2023-05-23'\n",
        "scaler_gbpusd = MinMaxScaler(feature_range=(0, 1))\n",
        "scaler_spx500 = MinMaxScaler(feature_range=(0, 1))\n",
        "modelPredict(n)\n",
        "n = addWeek(n)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cwL2PXSGXFDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(n)"
      ],
      "metadata": {
        "id": "YL2L-qSUVLA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_gbpusd = pdr.get_data_yahoo('GBPUSD=X', start='2023-01-20', end='2023-05-23')\n",
        "print(df_gbpusd.filter(['Close']).values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zH-xJezxpc9S",
        "outputId": "683a13a7-0f34-4b3b-b404-55e603b4c492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "[[1.23932624]\n",
            " [1.24063325]\n",
            " [1.23797619]\n",
            " [1.23292398]\n",
            " [1.2412492 ]\n",
            " [1.2415266 ]\n",
            " [1.24003017]\n",
            " [1.23536098]\n",
            " [1.23089039]\n",
            " [1.2390039 ]\n",
            " [1.22229958]\n",
            " [1.20451462]\n",
            " [1.20267475]\n",
            " [1.20545828]\n",
            " [1.20714629]\n",
            " [1.21168065]\n",
            " [1.20522583]\n",
            " [1.21521449]\n",
            " [1.21743369]\n",
            " [1.20397794]\n",
            " [1.19753313]\n",
            " [1.20297861]\n",
            " [1.20392001]\n",
            " [1.21093225]\n",
            " [1.20499349]\n",
            " [1.20177865]\n",
            " [1.19524288]\n",
            " [1.20615625]\n",
            " [1.20335495]\n",
            " [1.20299304]\n",
            " [1.19515729]\n",
            " [1.20284832]\n",
            " [1.20264578]\n",
            " [1.18277407]\n",
            " [1.18501663]\n",
            " [1.19225037]\n",
            " [1.20793366]\n",
            " [1.21713722]\n",
            " [1.21521449]\n",
            " [1.20692778]\n",
            " [1.21104956]\n",
            " [1.21876907]\n",
            " [1.22762644]\n",
            " [1.22250879]\n",
            " [1.22797322]\n",
            " [1.22815418]\n",
            " [1.22460032]\n",
            " [1.22975516]\n",
            " [1.2330457 ]\n",
            " [1.23136032]\n",
            " [1.23872757]\n",
            " [1.22869742]\n",
            " [1.24231315]\n",
            " [1.24984372]\n",
            " [1.24630785]\n",
            " [1.24390018]\n",
            " [1.24316251]\n",
            " [1.23921883]\n",
            " [1.24310076]\n",
            " [1.24926603]\n",
            " [1.2525301 ]\n",
            " [1.24001789]\n",
            " [1.23754716]\n",
            " [1.24254477]\n",
            " [1.24288452]\n",
            " [1.24409056]\n",
            " [1.24497342]\n",
            " [1.25      ]\n",
            " [1.24148035]\n",
            " [1.2471472 ]\n",
            " [1.24975002]\n",
            " [1.25576079]\n",
            " [1.24859536]\n",
            " [1.24766064]\n",
            " [1.25689721]\n",
            " [1.25833642]\n",
            " [1.26305687]\n",
            " [1.26127255]\n",
            " [1.26246679]\n",
            " [1.2626996 ]\n",
            " [1.25081301]\n",
            " [1.2450974 ]\n",
            " [1.2525208 ]\n",
            " [1.24843943]\n",
            " [1.24828053]\n",
            " [1.24123383]\n",
            " [1.24610591]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rules: go for the majority decision except when MAPE is 0. If MAPE is 0, look at weekly Candle, if last one is red that is the trend and interpret it as a sell signal and vice versa"
      ],
      "metadata": {
        "id": "HFuIk8IJ1rYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = '2023-05-23'"
      ],
      "metadata": {
        "id": "SOxFqzjByhEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "\n",
        "# Load the model from the SavedModel format\n",
        "model = keras.models.load_model('crutchless8.h5')\n",
        "model2 = keras.models.load_model('Bi3.h5')\n",
        "model3 = keras.models.load_model('GRU5.h5')"
      ],
      "metadata": {
        "id": "XVnIuuUHxUoR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}